class TestOptimizer extends TestCase {
    Run() {
        let input = new Float64Array([1.8886, 0.8443, -0.4153, -1.1099, 3.0217, -0.2078, 0.4149, -0.6675, -0.129, -0.5452, 0.0383, 0.2458, 0.7014, 0.4982, -1.0301])
        let target = new Float64Array([1.217, 2.1569, -0.1898, 0.2762, 0.7444, 0.6646, 0.6972, 0.183, 0.2508, 1.7344, 0.1816, 0.8196, -0.1508, -0.5587, 0.3551])
        let steps = 25

        let criterion = new HuberLoss()
        let learningRate = 0.187

        let runs = [
            {
                name: "SGD",
                optimizer: new SGD(learningRate, {regularizationType: "l2", lambda: 0.02}),
                steps: {
                    0: {
                        loss: 0.556056544,
                        grads: new Float64Array([0.04477333333333333, -0.06666666666666667, -0.015033333333333334, -0.06666666666666667, 0.06666666666666667, -0.058159999999999996, -0.018820000000000003, -0.0567, -0.025320000000000002, -0.06666666666666667, -0.009553333333333334, -0.038253333333333334, 0.056813333333333334, 0.06666666666666667, -0.06666666666666667]),
                        weights: new Float64Array([1.8731640226666668, 0.8536089846666667, -0.41093554466666665, -1.0932823073333335, 2.9979321753333332, -0.196146908, 0.416867614, -0.65440065, -0.12378270000000001, -0.5306942853333334, 0.039943231333333336, 0.2520340813333333, 0.6881526706666667, 0.4838700653333333, -1.0137807593333334]),
                    },
                    1: {
                        loss: 0.5464072066516201,
                        grads: new Float64Array([0.04374426817777778, -0.06666666666666667, -0.014742369644444444, -0.06666666666666667, 0.06666666666666667, -0.057383127199999995, -0.018688825733333338, -0.055826709999999995, -0.024972180000000004, -0.06666666666666667, -0.009443784577777779, -0.037837727911111105, 0.05593017804444445, 0.06666666666666667, -0.06666666666666667]),
                        weights: new Float64Array([1.857978211072649, 0.86288315373068, -0.4066418226061022, -1.0767267648372403, 2.97425324233092, -0.18468267377768002, 0.4188033395357733, -0.641513596799, -0.118649955042, -0.5162428220395201, 0.04155983136419111, 0.25816712898852445, 0.6751200363840623, 0.46959372462231996, -0.9975225526267602]),
                    },
                    24: {
                        loss: 0.3583363700849152,
                        grads: new Float64Array([0.024175430218812795, -0.06666666666666667, -0.009209365976921107, -0.06666666666666667, 0.06666666666666667, -0.04261001214906806, -0.016194398675019164, -0.0392201128288436, -0.018357989263736427, -0.06666666666666667, -0.007360591074917797, -0.02993452069587583, 0.03913598124595364, 0.05047373527853651, -0.06666666666666667]),
                        weights: new Float64Array([1.5692028261959987, 1.0668733548756963, -0.32499184078482707, -0.7125789451746244, 2.4534227212651984, 0.03332270771741752, 0.45561335019260973, -0.3964517030039621, -0.02104500376603204, -0.19837532536170022, 0.07230130956654557, 0.37479396754302996, 0.4272897536484132, 0.18822540213183547, -0.639914789231519]),
                    }
                }
            },
            {
                name: "MomentumSGD",
                optimizer: new MomentumSGD(learningRate, {regularizationType: "l2", lambda: 0.02, momentum: 0.9, dampening: 0.1}),
                steps: {
                    0: {
                        loss: 0.556056544,
                        grads: new Float64Array([0.04477333333333333, -0.06666666666666667, -0.015033333333333334, -0.06666666666666667, 0.06666666666666667, -0.058159999999999996, -0.018820000000000003, -0.0567, -0.025320000000000002, -0.06666666666666667, -0.009553333333333334, -0.038253333333333334, 0.056813333333333334, 0.06666666666666667, -0.06666666666666667]),
                        weights: new Float64Array([1.8731640226666668, 0.8536089846666667, -0.41093554466666665, -1.0932823073333335, 2.9979321753333332, -0.196146908, 0.416867614, -0.65440065, -0.12378270000000001, -0.5306942853333334, 0.039943231333333336, 0.2520340813333333, 0.6881526706666667, 0.4838700653333333, -1.0137807593333334]),
                    },
                    1: {
                        loss: 0.5464072066516201,
                        grads: new Float64Array([0.04374426817777778, -0.06666666666666667, -0.014742369644444444, -0.06666666666666667, 0.06666666666666667, -0.057383127199999995, -0.018688825733333338, -0.055826709999999995, -0.024972180000000004, -0.06666666666666667, -0.009443784577777779, -0.037837727911111105, 0.05593017804444445, 0.06666666666666667, -0.06666666666666667]),
                        weights: new Float64Array([1.8456044126320508, 0.8703338230242786, -0.4031431850121587, -1.0634263956868495, 2.9552300934311613, -0.17534131439991202, 0.420380619582196, -0.6310128871191, -0.11446765953780001, -0.5046328251689014, 0.042877079561105334, 0.26316449742300535, 0.6645007034123227, 0.4581244174934213, -0.9844610566974175]),
                    },
                    24: {
                        loss: 0.030123243999646835,
                        grads: new Float64Array([-0.031908816406272716, -0.02524014157394099, 0.006648210385947125, 0.011065342793357835, -0.02428179947308285, -0.00027029684892394546, -0.009045376202650652, 0.008374358202273538, 0.0005982668642888175, -0.034761135939685196, -0.0013901630695772771, -0.0072839461692801345, -0.008996149905210478, -0.004126926237178778, 0.009554161617316337]),
                        weights: new Float64Array([0.727386026283042, 1.7954810259399852, -0.08697180857502963, 0.46527407975931323, 0.31147042056460134, 0.6688359897528544, 0.5629191906441289, 0.31793473718126086, 0.26348578397369277, 1.2820553622167392, 0.16191660976241926, 0.7147759644776219, -0.29516689071953506, -0.6317581585208076, 0.5213369108560525]),
                    }
                }
            },
            {
                name: "Adam",
                optimizer: new Adam(learningRate, {regularizationType: "l2", lambda: 0.02}),
                steps: {
                    0: {
                        loss: 0.556056544,
                        grads: new Float64Array([0.04477333333333333, -0.06666666666666667, -0.015033333333333334, -0.06666666666666667, 0.06666666666666667, -0.058159999999999996, -0.018820000000000003, -0.0567, -0.025320000000000002, -0.06666666666666667, -0.009553333333333334, -0.038253333333333334, 0.056813333333333334, 0.06666666666666667, -0.06666666666666667]),
                        weights: new Float64Array([1.7016000226542156, 1.0312999624352235, -0.22830008012221997, -0.9229000210432321, 2.8347000147127464, -0.020800030008339798, 0.6018998222773024, -0.4805000266952139, 0.05799993297493439, -0.35820002410704765, 0.22529978719393007, 0.4327999439067479, 0.514400026397015, 0.31120002440275985, -0.8431000214280779]),
                    },
                    1: {
                        loss: 0.4318306744828508,
                        grads: new Float64Array([0.0323066681769477, -0.06666666666666667, -0.002566672008147998, -0.06666666666666667, 0.06666666666666667, -0.04569333533388932, -0.006353345181513174, -0.04423333511301426, -0.012853337801671041, -0.06666666666666667, 0.0029133191462620035, -0.025786670406216804, 0.044346668426467666, 0.05799333496018399, -0.06666666666666667]),
                        weights: new Float64Array([1.5167533193738065, 1.2177774275683826, -0.06778714544869752, -0.7361527356747979, 2.6478664295401595, 0.16270376354869112, 0.6459588435107062, -0.2963444843946938, 0.2273640660535296, -0.17149782308601141, 0.231221709942816, 0.6078611096383881, 0.33018967774506736, 0.12577804936874018, -0.6563582788380098]),
                    },
                    24: {
                        loss: 0.042771142525689095,
                        grads: new Float64Array([-0.005773228225800745, -0.039963749259775395, -0.000924314936349437, -0.008678264556482887, -0.047751659504241505, -0.01581455196800135, -0.012097948663322654, -0.012947450284582815, -0.006117938293256997, -0.01585592650042852, -0.004475193033523363, -0.009975952009806633, 0.012803417202736112, 0.02147985663436648, -0.01087220318240923]),
                        weights: new Float64Array([1.1270360459726088, 1.5987914622674184, -0.1938285975708824, 0.09760925388734994, 0.055571252808447456, 0.46727108941230217, 0.5081057288998582, 0.01932896305330146, 0.14033436295138152, 1.4249145884997485, 0.12664669994963165, 0.639862864149427, 0.012129481646360019, -0.24709865573178993, 0.14586653085091128]),
                    }
                }
            },
            {
                name: "Adamax",
                optimizer: new Adamax(learningRate, {regularizationType: "l2", lambda: 0.02}),
                steps: {
                    0: {
                        loss: 0.556056544,
                        grads: new Float64Array([0.04477333333333333, -0.06666666666666667, -0.015033333333333334, -0.06666666666666667, 0.06666666666666667, -0.058159999999999996, -0.018820000000000003, -0.0567, -0.025320000000000002, -0.06666666666666667, -0.009553333333333334, -0.038253333333333334, 0.056813333333333334, 0.06666666666666667, -0.06666666666666667]),
                        weights: new Float64Array([1.7016000226542156, 1.0312999624352235, -0.22830008012221994, -0.9229000210432321, 2.8347000147127464, -0.02080003000833977, 0.6018998222773024, -0.48050002669521386, 0.057999932974934415, -0.35820002410704765, 0.22529978719393007, 0.43279994390674803, 0.514400026397015, 0.31120002440275985, -0.8431000214280779]),
                    },
                    1: {
                        loss: 0.4318306744828508,
                        grads: new Float64Array([0.0323066681769477, -0.06666666666666667, -0.0025666720081479965, -0.06666666666666667, 0.06666666666666667, -0.045693335333889314, -0.006353345181513174, -0.04423333511301425, -0.01285333780167104, -0.06666666666666667, 0.0029133191462620035, -0.025786670406216797, 0.044346668426467666, 0.05799333496018399, -0.06666666666666667]),
                        weights: new Float64Array([1.5337558472083885, 1.2110853820577798, -0.10952420304795303, -0.7398591948655238, 2.6504118289517318, 0.14076492169716173, 0.637340886693243, -0.31610620543028356, 0.1879586400849875, -0.1757628924852779, 0.23078542237176294, 0.5720926350085153, 0.34975159183936166, 0.13997195445598165, -0.6601350253381582]),
                    },
                    24: {
                        loss: 0.03061116105816698,
                        grads: new Float64Array([-0.02410991887706851, -0.038977756822950585, 0.0053688766485816015, 0.007690513862763807, -0.03617326411933653, -0.012367954096964947, -0.010643658092917889, -0.0022142818236968137, -0.002746110492604144, -0.006456175651115773, -0.0014301687424364922, -0.014155016155728036, 0.001419320792705638, 0.005046866564846135, 0.005846813939403491]),
                        weights: new Float64Array([0.8770019770115405, 1.563271725525537, -0.10955842500734737, 0.36422325383688137, 0.19250552894035922, 0.4652903726353271, 0.5458791058511658, 0.13135628430203747, 0.2183155693162739, 1.607139334410706, 0.1575533465454759, 0.619774371766124, -0.11072952806762981, -0.4610360009066331, 0.4150649631717563]),
                    }
                }
            },
            {
                name: "Adadelta",
                optimizer: new Adadelta(learningRate, {regularizationType: "l2", lambda: 0.02}),
                steps: {
                    0: {
                        loss: 0.556056544,
                        grads: new Float64Array([0.04477333333333333, -0.06666666666666667, -0.015033333333333334, -0.06666666666666667, 0.06666666666666667, -0.058159999999999996, -0.018820000000000003, -0.0567, -0.025320000000000002, -0.06666666666666667, -0.009553333333333334, -0.038253333333333334, 0.056813333333333334, 0.06666666666666667, -0.06666666666666667]),
                        weights: new Float64Array([1.8880090875373672, 0.8448901563847011, -0.41471400840462624, -1.1093090281374478, 3.0211088370199533, -0.20720941400946538, 0.4154663224922784, -0.6669092557112597, -0.12841241628903236, -0.5446091448448954, 0.03885641338654204, 0.24638870332428459, 0.7008092423651678, 0.49760915694341595, -1.029509041930854]),
                    },
                    1: {
                        loss: 0.5556302718188262,
                        grads: new Float64Array([0.044733939169157806, -0.06666666666666667, -0.014994267226975083, -0.06666666666666667, 0.06666666666666667, -0.05812062760063102, -0.018782245167181445, -0.056660617047417317, -0.025280827752602156, -0.06666666666666667, -0.009516239107563865, -0.038214086445047694, 0.05677394949101119, 0.06666666666666667, -0.06666666666666667]),
                        weights: new Float64Array([1.8874030142472658, 0.8454955438051691, -0.41411356475939376, -1.1087027521272224, 3.020502348275174, -0.20660374231798004, 0.41604534574386304, -0.6663033912907718, -0.12781019511394404, -0.5440029972821404, 0.039424776984774465, 0.24699218837781362, 0.7002033615466292, 0.4970030226562934, -1.0289027811430056]),
                    },
                    24: {
                        loss: 0.544775000553664,
                        grads: new Float64Array([0.04372370774525129, -0.06666666666666667, -0.01400889933016442, -0.06666666666666667, 0.06666666666666667, -0.057113056655800166, -0.017856950394161505, -0.05565182768127135, -0.024289000921819265, -0.06666666666666667, -0.008616406451698784, -0.037217214091701194, 0.055765052051971256, 0.06666666666666667, -0.06666666666666667]),
                        weights: new Float64Array([1.8721621204347103, 0.8607795330213708, -0.39926896351258195, -1.0933782184468916, 3.0051656779306004, -0.19140573318733123, 0.42995116242588494, -0.6510857632839223, -0.11286340040757699, -0.5286850167299463, 0.052936462789905894, 0.26201911179282034, 0.6849839916975369, 0.4816856979714096, -1.0135790463196808]),
                    }
                }
            },
            {
                name: "Adagrad",
                optimizer: new Adagrad(learningRate, {regularizationType: "l2", lambda: 0.02}),
                steps: {
                    0: {
                        loss: 0.556056544,
                        grads: new Float64Array([0.04477333333333333, -0.06666666666666667, -0.015033333333333334, -0.06666666666666667, 0.06666666666666667, -0.058159999999999996, -0.018820000000000003, -0.0567, -0.025320000000000002, -0.06666666666666667, -0.009553333333333334, -0.038253333333333334, 0.056813333333333334, 0.06666666666666667, -0.06666666666666667]),
                        weights: new Float64Array([1.7016000002265423, 1.0312999996243521, -0.22830000080122254, -0.9229000002104324, 2.8347000001471274, -0.02080000030008347, 0.6018999982227713, -0.48050000026695217, 0.057999999329749086, -0.3582000002410705, 0.2252999978719369, 0.43279999943906733, 0.5144000002639701, 0.3112000002440276, -0.8431000002142808]),
                    },
                    1: {
                        loss: 0.4318306578348285,
                        grads: new Float64Array([0.032306666681769486, -0.06666666666666667, -0.0025666667200815027, -0.06666666666666667, 0.06666666666666667, -0.045693333353338896, -0.00635333345181525, -0.044233333351130145, -0.012853333378016729, -0.06666666666666667, 0.00291333319146246, -0.025786666704062176, 0.04434666668426468, 0.057993333349601835, -0.06666666666666667]),
                        weights: new Float64Array([1.5844567136823258, 1.1582712637912906, -0.1736466987792777, -0.7935432511600163, 2.7044600533916023, 0.09042861684175925, 0.5130134200622066, -0.3665389892950062, 0.13028283938472945, -0.22927675537197867, 0.10466145309868494, 0.5182678574485451, 0.400198575642805, 0.19109031334605697, -0.7137974852944124]),
                    },
                    24: {
                        loss: 0.06400729525079189,
                        grads: new Float64Array([-0.015216337948304149, -0.033809774982284845, 0.0029199999999121374, -0.016462808365167055, 0.05281679675375792, -0.010758089742361202, -0.010726153846205566, -0.00410139381159079, -0.003858461859216646, -0.05682445199954952, -0.002793846154167166, -0.012609293043593046, 0.0037083948459003006, 0.011439521611061654, -0.01695802642158702]),
                        weights: new Float64Array([0.9833925174098543, 1.6512573069114385, -0.14600000000044747, 0.041354588378535, 1.5074242602557433, 0.5045171336530514, 0.5363076923079514, 0.12405214530560406, 0.19292307463747307, 0.9069084283814374, 0.13969230769402138, 0.6304609891099909, -0.09790176925283013, -0.39174795299648485, 0.11242149261940067]),
                    }
                }
            },
            {
                name: "RMSprop (not centered)",
                optimizer: new RMSprop(learningRate, {regularizationType: "l2", lambda: 0.02, centered: false}),
                steps: {
                    0: {
                        loss: 0.556056544,
                        grads: new Float64Array([0.04477333333333333, -0.06666666666666667, -0.015033333333333334, -0.06666666666666667, 0.06666666666666667, -0.058159999999999996, -0.018820000000000003, -0.0567, -0.025320000000000002, -0.06666666666666667, -0.009553333333333334, -0.038253333333333334, 0.056813333333333334, 0.06666666666666667, -0.06666666666666667]),
                        weights: new Float64Array([0.018602265419085162, 2.7142962435291267, 1.4546919878089009, 0.7600978956789393, 1.151701471273581, 1.6621969991703578, 2.2848822278822665, 1.2024973304820399, 1.740993297515062, 1.3247975892980293, 1.9082787196109587, 2.115794390689944, -1.1685973603018567, -1.3717975597268803, 0.8398978571944211]),
                    },
                    1: {
                        loss: 0.5577246281189692,
                        grads: new Float64Array([-0.06666666666666667, 0.03715974956860846, 0.06666666666666667, 0.03225985971192928, 0.02715343141823873, 0.06650646661135719, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, -0.027306827380131377, 0.06666666666666667, 0.06666666666666667, -0.06666666666666667, -0.054206503981792026, 0.03231985714629474]),
                        weights: new Float64Array([1.1931366987630139, 1.070007270870067, -0.36263250900252686, -0.124321413097631, 0.4619192260247834, 0.07401071912858703, 0.422948242940983, -0.2803647621236609, -0.06274284925719109, 1.3444427771098029, 0.044750617178163976, 0.32682323187882467, 0.30386714522728053, -0.005117328196760473, -0.08080646900656074]),
                    },
                    24: {
                        loss: 0.016998324966898255,
                        grads: new Float64Array([-0.018722974818540652, -0.03318308227305186, 0.002915540287150337, -0.004249731082742329, -0.011452307692308412, -0.010224615402960957, -0.010726157008505943, -0.002815384748482064, -0.0038585838822590367, -0.01177875904835554, -0.0027940430297261026, -0.012609231545103813, 0.0023200001397581825, 0.00859538515687247, -0.005463586703102523]),
                        weights: new Float64Array([0.9361528149273433, 1.6591538933213226, -0.14594695804165955, 0.21246686607368986, 0.5726153846153882, 0.5112307693588497, 0.5363077209802273, 0.1407692317755493, 0.19292432204924995, 1.1294118554636214, 0.1396944391758279, 0.6304615448424232, -0.11600000105886175, -0.42976923509687553, 0.27315926581612726]),
                    }
                }
            },
            {
                name: "RMSprop (centered)",
                optimizer: new RMSprop(learningRate, {regularizationType: "l2", lambda: 0.02, centered: true}),
                steps: {
                    0: {
                        loss: 0.556056544,
                        grads: new Float64Array([0.04477333333333333, -0.06666666666666667, -0.015033333333333334, -0.06666666666666667, 0.06666666666666667, -0.058159999999999996, -0.018820000000000003, -0.0567, -0.025320000000000002, -0.06666666666666667, -0.009553333333333334, -0.038253333333333334, 0.056813333333333334, 0.06666666666666667, -0.06666666666666667]),
                        weights: new Float64Array([0.009181573767365947, 2.7237169201197413, 1.4641126214125786, 0.7695185889579097, 1.142280771600198, 1.6716176833936984, 2.2943027629015114, 1.211918018051958, 1.7504139443480429, 1.3342182794822466, 1.917699219193493, 2.125215048565059, -1.1780180481729845, -1.3812182496123997, 0.8493185500846594]),
                    },
                    1: {
                        loss: 0.5643506319909439,
                        grads: new Float64Array([-0.06666666666666667, 0.03778779467464943, 0.06666666666666667, 0.03288790593052731, 0.02652538477334653, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, -0.026678781367850225, 0.06666666666666667, 0.06666666666666667, -0.06666666666666667, -0.05483454997415998, 0.03294790333897729]),
                        weights: new Float64Array([1.185856166323812, 1.0747425810921114, -0.3583781339625072, -0.12734022209144646, 0.4564906019404721, 0.08104401231536262, 0.42469458390992343, -0.2723478571435485, -0.05802416797031329, 1.334082307718197, 0.04631487907231313, 0.33198227385686585, 0.2958419918480464, -0.00819792032961808, -0.08352842390844051]),
                    },
                    24: {
                        loss: 0.021493230654582994,
                        grads: new Float64Array([-0.01872297267948555, -0.033183080756389816, 0.0029154113316651447, -0.004249661210965311, -0.011452307692309613, -0.010224615401908917, -0.010726157311451271, -0.0028153847538015513, -0.0038585869470991758, -0.02716729922026473, -0.0027940592577807453, -0.012609231562635551, 0.002320000145442293, 0.008595385031901796, -0.005463511984749639]),
                        weights: new Float64Array([0.9361527912256309, 1.6591538794796066, -0.14594533200341184, 0.21246609002006467, 0.5726153846153945, 0.5112307693513053, 0.5363077238347331, 0.14076923181823264, 0.19292435512693826, 1.3440775710810424, 0.13969462203231964, 0.6304615449950649, -0.11600000110455226, -0.42976923406423156, 0.27315843805849643]),
                    }
                }
            }
        ]

        for (let run of runs) {
            console.log(`%cTest ${run.name}`, "font-weight: bold")

            this.TestOptimizer(run.optimizer, criterion, input, target, steps, run.steps)
            console.log()
        }
    }

    TestOptimizer(optimizer, criterion, input, target, steps, targetResults) {
        let weights = new Float64Array(input.length)
        let params1 = new Float64Array(input.length).fill(0)
        let params2 = new Float64Array(input.length).fill(0)

        for (let i = 0; i < input.length; i++)
            weights[i] = input[i]

        for (let step = 0; step < steps; step++) {
            let loss = criterion.Backward(weights, target, weights.length)

            for (let i = 0; i < input.length; i++)
                optimizer.Step(weights, criterion.grads, params1, params2, i)

            optimizer.UpdateEpoch()

            if (!targetResults[step])
                continue

            console.log(`- step ${step}:`)
            this.CheckEqualFloat(`  - test loss`, loss, targetResults[step].loss)
            this.CheckEqualValues(`  - test grads`, criterion.grads, targetResults[step].grads)
            this.CheckEqualValues(`  - test weights`, weights, targetResults[step].weights)
        }
    }
}
